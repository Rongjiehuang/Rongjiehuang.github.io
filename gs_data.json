{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "iRHBUsgAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Rongjie Huang", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=iRHBUsgAAAAJ&citpid=3", "affiliation": "FAIR, Zhejiang University", "organization": 1118375729466322660, "interests": ["Multimedia Computing", "Speech", "Natural Language Processing"], "email_domain": "@zju.edu.cn", "homepage": "http://rongjiehuang.github.io/", "citedby": 2366, "publications": {"iRHBUsgAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make-An-Audio: Text-to-audio generation with prompt-enhanced diffusion models", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:KlAtU1dfN6UC", "num_citations": 319, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14204166098403262471", "cites_id": ["14204166098403262471"]}, "iRHBUsgAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ProDiff: Progressive Fast Diffusion Model For High-Quality Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:Se3iqnhoufwC", "num_citations": 182, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9223505264010200019", "cites_id": ["9223505264010200019"]}, "iRHBUsgAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audiogpt: Understanding and generating speech, music, sound, and talking head", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:_kc_bZDykSQC", "num_citations": 179, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10625702268349818855", "cites_id": ["10625702268349818855"]}, "iRHBUsgAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis", "pub_year": "2022"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:YsMSGLbcyi4C", "num_citations": 171, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2088823687859195371", "cites_id": ["2088823687859195371"]}, "iRHBUsgAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Bilateral denoising diffusion models", "pub_year": "2021"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:2osOgNQ5qMEC", "num_citations": 144, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9819196866307115344,8410367099889699879", "cites_id": ["9819196866307115344", "8410367099889699879"]}, "iRHBUsgAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Hifi-codec: Group-residual vector quantization for high fidelity audio codec", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:M3ejUd6NZC8C", "num_citations": 111, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16848014406171770614", "cites_id": ["16848014406171770614"]}, "iRHBUsgAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Uniaudio: An audio foundation model toward universal audio generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:HDshCWvjkbEC", "num_citations": 106, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6416249801268158267", "cites_id": ["6416249801268158267"]}, "iRHBUsgAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-singer: Fast multi-singer singing voice vocoder with a large-scale corpus", "pub_year": "2021"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:zYLM7Y9cAGgC", "num_citations": 106, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2358855456085494126", "cites_id": ["2358855456085494126"]}, "iRHBUsgAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:eQOLeE2rZwMC", "num_citations": 98, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13191102001080802763", "cites_id": ["13191102001080802763"]}, "iRHBUsgAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Instructtts: Modelling expressive tts in discrete latent space with natural language style prompt", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:Zph67rFs4hoC", "num_citations": 88, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16890941306445601074", "cites_id": ["16890941306445601074"]}, "iRHBUsgAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M4Singer: a Multi-Style, Multi-Singer and Musical Score Provided Mandarin Singing Corpus", "pub_year": "2022"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:LkGwnXOMwfcC", "num_citations": 79, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1634477637622720706", "cites_id": ["1634477637622720706"]}, "iRHBUsgAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mega-tts: Zero-shot text-to-speech at scale with intrinsic inductive bias", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:ZeXyd9-uunAC", "num_citations": 77, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15692405188854768212", "cites_id": ["15692405188854768212"]}, "iRHBUsgAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SingGAN: Generative Adversarial Network For High-Fidelity Singing Voice Generation", "pub_year": "2022"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:roLk4NBRz8UC", "num_citations": 64, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1698516610881405813", "cites_id": ["1698516610881405813"]}, "iRHBUsgAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make-an-audio 2: Temporal-enhanced text-to-audio generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:7PzlFSSx8tAC", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13517159671265524532", "cites_id": ["13517159671265524532"]}, "iRHBUsgAAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation", "pub_year": "2022"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:ULOm3_A8WrAC", "num_citations": 49, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15292967138191810315", "cites_id": ["15292967138191810315"]}, "iRHBUsgAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model", "pub_year": "2021"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:9yKSN-GCB0IC", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15315350381922618364", "cites_id": ["15315350381922618364"]}, "iRHBUsgAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Geneface++: Generalized and stable real-time audio-driven 3d talking face generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:4TOpqqG69KYC", "num_citations": 35, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=408392048948677980", "cites_id": ["408392048948677980"]}, "iRHBUsgAAAAJ:vV6vV6tmYwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make-a-voice: Revisiting voice large language models as scalable multilingual and multitask learners", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:vV6vV6tmYwMC", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12763739973148023166,1604035471441920381", "cites_id": ["12763739973148023166", "1604035471441920381"]}, "iRHBUsgAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real3d-portrait: One-shot realistic 3d talking portrait synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:4JMBOYKVnBMC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4610920972123504276", "cites_id": ["4610920972123504276"]}, "iRHBUsgAAAAJ:2P1L_qKh6hAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wavtokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:2P1L_qKh6hAC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11096367345508634509", "cites_id": ["11096367345508634509"]}, "iRHBUsgAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Chat-3d v2: Bridging 3d scene and large language models with object identifiers", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:e5wmG9Sq2KIC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9819100763177515104", "cites_id": ["9819100763177515104"]}, "iRHBUsgAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mixspeech: Cross-modality self-learning with audio-visual stream mixup for visual speech translation and recognition", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:YOwf2qJgpHMC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2782308253975293934", "cites_id": ["2782308253975293934"]}, "iRHBUsgAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Clapspeech: Learning prosody from text context with contrastive language-audio pre-training", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:4DMP91E08xMC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11061604911451895335", "cites_id": ["11061604911451895335"]}, "iRHBUsgAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RMSSinger: realistic-music-score based singing voice synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:aqlVkmm33-oC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10533965237930127174", "cites_id": ["10533965237930127174"]}, "iRHBUsgAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:_Qo2XoVZTnwC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9942954876960767861", "cites_id": ["9942954876960767861"]}, "iRHBUsgAAAAJ:j3f4tGmQtD8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Language-codec: Reducing the gaps between discrete codec representation and speech language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:j3f4tGmQtD8C", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15333061713300156908", "cites_id": ["15333061713300156908"]}, "iRHBUsgAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Av-transpeech: Audio-visual robust speech-to-speech translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:9ZlFYXVOiuMC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3031965472100444937", "cites_id": ["3031965472100444937"]}, "iRHBUsgAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vit-tts: visual text-to-speech with scalable diffusion transformer", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:mVmsd5A6BfQC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14147897746414758233", "cites_id": ["14147897746414758233"]}, "iRHBUsgAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VarietySound: Timbre-Controllable Video to Sound Generation via Unsupervised Information Disentanglement", "pub_year": "2022"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:hqOjcs7Dif8C", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2333085745106701374", "cites_id": ["2333085745106701374"]}, "iRHBUsgAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Frieren: Efficient Video-to-Audio Generation with Rectified Flow Matching", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:hMod-77fHWUC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12114926302115863266", "cites_id": ["12114926302115863266"]}, "iRHBUsgAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FluentSpeech: Stutter-Oriented Automatic Speech Editing with Context-Aware Diffusion Models", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:QIV2ME_5wuYC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7922113499487900716", "cites_id": ["7922113499487900716"]}, "iRHBUsgAAAAJ:zA6iFVUQeVQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Chat-scene: Bridging 3d scene and large language models with object identifiers", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:zA6iFVUQeVQC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17772435643977512045", "cites_id": ["17772435643977512045"]}, "iRHBUsgAAAAJ:ns9cj8rnVeAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UniAudio 1.5: Large Language Model-driven Audio Codec is A Few-shot Audio Task Learner", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:ns9cj8rnVeAC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9610513952615411361", "cites_id": ["9610513952615411361"]}, "iRHBUsgAAAAJ:maZDTaKrznsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:maZDTaKrznsC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14417271216765405515", "cites_id": ["14417271216765405515"]}, "iRHBUsgAAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UniAudio: Towards Universal Audio Generation with Large Language Models"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:GnPB-g6toBAC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7553768456221728553", "cites_id": ["7553768456221728553"]}, "iRHBUsgAAAAJ:NMxIlDl6LWMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AudioLCM: Text-to-Audio Generation with Latent Consistency Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:NMxIlDl6LWMC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14141182423302675181", "cites_id": ["14141182423302675181"]}, "iRHBUsgAAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:hFOr9nPyWt4C", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12603739386764076775", "cites_id": ["12603739386764076775"]}, "iRHBUsgAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastDiff 2: Revisiting and incorporating GANs and diffusion models in high-fidelity speech synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:IWHjjKOFINEC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5865263432404926087", "cites_id": ["5865263432404926087"]}, "iRHBUsgAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Detector guidance for multi-object text-to-image generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:L8Ckcad2t8MC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11690234322079605255", "cites_id": ["11690234322079605255"]}, "iRHBUsgAAAAJ:BqipwSGYUEgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FreeBind: Free Lunch in Unified Multimodal Space via Knowledge Fusion"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:BqipwSGYUEgC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16449970934698418261", "cites_id": ["16449970934698418261"]}, "iRHBUsgAAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Controlspeech: Towards simultaneous zero-shot speaker cloning and zero-shot language style control with decoupled codec", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:blknAaTinKkC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=403976369840040732", "cites_id": ["403976369840040732"]}, "iRHBUsgAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:RHpTSmoSYBkC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17335056964216082744", "cites_id": ["17335056964216082744"]}, "iRHBUsgAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unisinger: Unified end-to-end singing voice synthesis with cross-modality information matching", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:TQgYirikUcIC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16431312941436321345", "cites_id": ["16431312941436321345"]}, "iRHBUsgAAAAJ:R3hNpaxXUhUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffusion denoising process for perceptron bias in out-of-distribution detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:R3hNpaxXUhUC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10567998091823456008", "cites_id": ["10567998091823456008"]}, "iRHBUsgAAAAJ:NaGl4SEjCO4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omnibind: Large-scale omni multimodal representation via binding spaces", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:NaGl4SEjCO4C", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15812878167712032072", "cites_id": ["15812878167712032072"]}, "iRHBUsgAAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Molecule-Space: Free Lunch in Unified Multimodal Space via Knowledge Fusion", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:k_IJM867U9cC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15657380580640127305", "cites_id": ["15657380580640127305"]}, "iRHBUsgAAAAJ:hC7cP41nSMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Contrastive token-wise meta-learning for unseen performer visual temporal-aligned translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:hC7cP41nSMkC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6919126084284083155", "cites_id": ["6919126084284083155"]}, "iRHBUsgAAAAJ:g5m5HwL7SMYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-next: Making lumina-t2x stronger and faster with next-dit", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:g5m5HwL7SMYC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15035790787388684947", "cites_id": ["15035790787388684947"]}, "iRHBUsgAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prosody-TTS: Improving Prosody with Masked Autoencoder and Conditional Diffusion Model For Expressive Text-to-Speech", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:qUcmZB5y_30C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6700848495971978849", "cites_id": ["6700848495971978849"]}, "iRHBUsgAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A rd-t network for hand gesture recognition based on millimeter-wave sensor", "pub_year": "2020"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:d1gkVwhDpl0C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8141374826143006366", "cites_id": ["8141374826143006366"]}, "iRHBUsgAAAAJ:70eg2SAEIzsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Simplespeech 2: Towards simple and efficient text-to-speech with flow-based scalar latent transformer diffusion models", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:70eg2SAEIzsC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12788614326807710009", "cites_id": ["12788614326807710009"]}, "iRHBUsgAAAAJ:bEWYMUwI8FkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "3D-Speaker-Toolkit: An Open Source Toolkit for Multi-modal Speaker Verification and Diarization", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:bEWYMUwI8FkC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5983358091608000997", "cites_id": ["5983358091608000997"]}, "iRHBUsgAAAAJ:r0BpntZqJG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural Language Prompt", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:r0BpntZqJG4C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10305936552962695765", "cites_id": ["10305936552962695765"]}, "iRHBUsgAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:qxL8FJ1GzNcC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3124350401729850271", "cites_id": ["3124350401729850271"]}, "iRHBUsgAAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Text-to-Song: Towards Controllable Music Generation Incorporating Vocals and Accompaniment", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:ZHo1McVdvXMC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1941313923866643833", "cites_id": ["1941313923866643833"]}, "iRHBUsgAAAAJ:rO6llkc54NcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Frieren: Efficient Video-to-Audio Generation Network with Rectified Flow Matching", "pub_year": "2025"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:rO6llkc54NcC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4664075196182723558", "cites_id": ["4664075196182723558"]}, "iRHBUsgAAAAJ:lSLTfruPkqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AudioLCM: Efficient and High-Quality Text-to-Audio Generation with Minimal Inference Steps", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:lSLTfruPkqcC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5288166097147531298", "cites_id": ["5288166097147531298"]}, "iRHBUsgAAAAJ:RYcK_YlVTxYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VoiceTuner: Self-Supervised Pre-training and Efficient Fine-tuning For Voice Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:RYcK_YlVTxYC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2734032292025936296", "cites_id": ["2734032292025936296"]}, "iRHBUsgAAAAJ:RGFaLdJalmkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Accompanied Singing Voice Synthesis with Fully Text-controlled Melody", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:RGFaLdJalmkC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11725362032593030706", "cites_id": ["11725362032593030706"]}, "iRHBUsgAAAAJ:JV2RwH3_ST0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Robust Singing Voice Transcription Serves Synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:JV2RwH3_ST0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=425946306691459202", "cites_id": ["425946306691459202"]}, "iRHBUsgAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wav2sql: Direct generalizable speech-to-sql parsing", "pub_year": "2023"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:Wp0gIr-vW9MC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8348701222387314867", "cites_id": ["8348701222387314867"]}, "iRHBUsgAAAAJ:O3NaXMp0MMsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "InstructSpeech: Following Speech Editing Instructions via Large Language Models"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:O3NaXMp0MMsC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16502846156364932331", "cites_id": ["16502846156364932331"]}, "iRHBUsgAAAAJ:M05iB0D1s5AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes", "pub_year": "2025"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:M05iB0D1s5AC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6584164374916365642", "cites_id": ["6584164374916365642"]}, "iRHBUsgAAAAJ:pqnbT2bcN3wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FlashAudio: Rectified Flows for Fast and High-Fidelity Text-to-Audio Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:pqnbT2bcN3wC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16163085057520483867", "cites_id": ["16163085057520483867"]}, "iRHBUsgAAAAJ:J_g5lzvAfSwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MEDIC: Zero-shot Music Editing with Disentangled Inversion Control", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:J_g5lzvAfSwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10706180370784119878", "cites_id": ["10706180370784119878"]}, "iRHBUsgAAAAJ:YFjsv_pBGBYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-Supervised Singing Voice Pre-Training towards Speech-to-Singing Conversion", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:YFjsv_pBGBYC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10274893363351855377", "cites_id": ["10274893363351855377"]}, "iRHBUsgAAAAJ:isC4tDSrTZIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TETA: Temporal-Enhanced Text-to-Audio Generation"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:isC4tDSrTZIC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12856513641027503156", "cites_id": ["12856513641027503156"]}, "iRHBUsgAAAAJ:cFHS6HbyZ2cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios", "pub_year": "2025"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:cFHS6HbyZ2cC", "num_citations": 0}, "iRHBUsgAAAAJ:3s1wT3WcHBgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MoMu-Diffusion: On Learning Long-Term Motion-Music Synchronization and Correspondence", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:3s1wT3WcHBgC", "num_citations": 0}, "iRHBUsgAAAAJ:SeFeTyx0c_EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OmniSep: Unified Omni-Modality Sound Separation with Query-Mixup", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:SeFeTyx0c_EC", "num_citations": 0}, "iRHBUsgAAAAJ:ldfaerwXgEUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:ldfaerwXgEUC", "num_citations": 0}, "iRHBUsgAAAAJ:35N4QoGY0k4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Integrating Audio, Visual, and Semantic Information for Enhanced Multimodal Speaker Diarization", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:35N4QoGY0k4C", "num_citations": 0}, "iRHBUsgAAAAJ:u_35RYKgDlwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AVSET-10M: An Open Large-Scale Audio-Visual Dataset with High Correspondence", "pub_year": "2024"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:u_35RYKgDlwC", "num_citations": 0}, "iRHBUsgAAAAJ:dfsIfKJdRG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:dfsIfKJdRG4C", "num_citations": 0}, "iRHBUsgAAAAJ:4OULZ7Gr8RgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MultiBand: Multi-Task Song Generation with Personalized Prompt-Based Control"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:4OULZ7Gr8RgC", "num_citations": 0}, "iRHBUsgAAAAJ:fPk4N6BV_jEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Noise-Robust Audio-Visual Speech-Driven Body Language Synthesis"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:fPk4N6BV_jEC", "num_citations": 0}, "iRHBUsgAAAAJ:TFP_iSt0sucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MVoice: Multilingual Unified Voice Generation With Discrete Representation at Scale"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:TFP_iSt0sucC", "num_citations": 0}, "iRHBUsgAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HarmonyLM: Advancing Unified Large-Scale Language Modeling for Sound and Music Generation"}, "filled": false, "author_pub_id": "iRHBUsgAAAAJ:iH-uZ7U-co4C", "num_citations": 0}}, "citedby5y": 2363, "hindex": 22, "hindex5y": 22, "i10index": 35, "i10index5y": 35, "cites_per_year": {"2022": 95, "2023": 550, "2024": 1508, "2025": 200}, "updated": "2025-02-19 08:25:31.265468"}