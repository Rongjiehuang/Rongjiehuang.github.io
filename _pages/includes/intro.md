**Rongjie Huang (ÈªÑËûçÊù∞)** is a Second-Year Master's student **(expected to graduate at 2024.03)** in the College of Computer Science and Software at [Zhejiang University](https://www.zju.edu.cn/english/), supervised by [Prof. Zhou Zhao](https://person.zju.edu.cn/zhaozhou). I collaborate with the CMU Speech Team led by [Shinji Watanabe](https://scholar.google.com/citations?user=U5xRA6QAAAAJ). I also have a close collaboration with Speech Research Team at Zhejiang University and ByteDance ([Yi Ren](https://github.com/RayeRen) and [Jinglin Liu](https://github.com/MoonInTheRiver)). I am a research intern at [Tencent AI Lab (Seattle Lab)](https://ai.tencent.com/ailab/en/index), where I work with [Chunlei Zhang](https://scholar.google.com/citations?hl=zh-CN&user=NCKZGb0AAAAJ&view_op=list_works&sortby=pubdate) and [Dong Yu](https://scholar.google.com/citations?user=tMY31_gAAAAJ&hl=zh-CN). 

My research interest includes generative AI for speech/sing/audio and spoken language processing. I have published **20+** papers at the top international AI conferences such as **NeurIPS/ICLR/ICML/ACL/IJCAI/ACM-MM**.

**I am actively looking for academic collaboration, feel free to drop me an email.**

Prior to that, I obtained Bachelor‚Äôs degree at Zhejiang University, supervised by [Prof. Zhi-Wei Hsu](https://person.zju.edu.cn/0014142) and [Prof. Hang-Fang Zhao](https://person.zju.edu.cn/0012062), where I minored in the intensive training program of innovation and entrepreneurship[(ITP)](http://itper.org/index.php/Index).

<!-- Rongjie aims at developing data-driven methods to study the interconnected world and investigates scientific and industrial problems. His research focuses on **multimodal (speech/sing/audio) synthesis, speech translation, and self-supervised learning**.  -->


# üî• News
- *2023.05*: 8 papers are accepted by ACL 2023!
- *2023.04*: [AudioGPT](https://github.com/AIGC-Audio/AudioGPT) and [AcademiCodec](https://github.com/yangdongchao/AcademiCodec) come out! 
- *2023.04*: One papers is accepted by ICML 2023!
- *2023.02*: Make-An-Audio comes out! Media coverage: [Heart of Machine](https://mp.weixin.qq.com/s/fphIJ13RWRIgGNTwYO06bw), [ByteDance](https://zhuanlan.zhihu.com/p/605228032), and [Twitter](https://twitter.com/_akhaliq/status/1619589070329348096).
- *2023.01*: One papers is accepted by ICLR 2023!
- *2022.09*: Two papers are accepted by NeurIPS 2022!
- *2022.02*: We release a diffusion text-to-speech pipeline [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue)](https://huggingface.co/spaces/Rongjiehuang/ProDiff) using ProDiff [![](https://img.shields.io/github/stars/Rongjiehuang/prodiff?style=social&label=Code+Stars)](https://github.com/Rongjiehuang/prodiff) and FastDiff [![](https://img.shields.io/github/stars/Rongjiehuang/FastDiff?style=social&label=Code+Stars)](https://github.com/Rongjiehuang/FastDiff). Welcome to STAR and FORK!
- *2022.06*: Two papers are accepted by ACM-MM 2022!
- *2022.04*: One paper is accepted by IJCAI 2022
