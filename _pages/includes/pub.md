# üìù Publications 
His recent works include **GenerSpeech (NeurIPS 2022)** for domain-generalizable text-to-speech, **FastDiff (IJCAI 2022) / ProDiff (ACM-MM 2022a)** for diffusion text-to-speech, and **SingGAN (ACM-MM 2022b) / Multi-Singer (ACM-MM 2021)** for singing voice synthesis. Most of the research has code open-sourced at [GitHub](https://github.com/Rongjiehuang). 


## 2022

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2022</div><img src='images/generspeech.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech.](https://arxiv.org/abs/2205.07211) **Rongjie Huang**, Yi Ren, Jinglin Liu, Chenye Cui, and Zhou Zhao. **NeurIPS, 2022**

- Code will be released soon.

</div>
</div>


- [M4Singer: a Multi-Style, Multi-Singer and Musical Score Provided Mandarin Singing Corpus.](https://arxiv.org/abs/2205.07211) Lichao Zhang, Ruiqi Li, Shoutong Wang, Liqun Deng, Jinglin Liu, Yi Ren, Jinzheng He, **Rongjie Huang**, Jieming Zhu, Xiao Chen, and Zhou Zhao. **NeurIPS, 2022**


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICJAI 2022</div><img src='images/fastdiff.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis.](https://arxiv.org/abs/2204.09934) **Rongjie Huang**, Max W.Y. Lam, Jun Wang, Dan Su, Dong Yu, Yi Ren, and Zhou Zhao. **IJCAI, 2022(oral)** 

- **Impact**: Our work are promoted by different media and forums, such as [Tencent AI Lab](https://mp.weixin.qq.com/s/GmLzLw3GnDsK0OuUpgEySQ), [Speech Home](https://mp.weixin.qq.com/s/BWf_uZdG0icWk5odChxhuA), and [Twitter](https://twitter.com/_akhaliq/status/1517308526691065856). We have code released at [![](https://img.shields.io/github/stars/Rongjiehuang/FastDiff?style=social&label=Code+Stars)](https://github.com/Rongjiehuang/FastDiff), which is a [Trending Project at both Github and Paperwithcode.](https://twitter.com/pythontrending/status/1528332486257819651)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM Multimedia 2022</div><img src='images/prodiff.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [ProDiff: Progressive Fast Diffusion Model for High-Quality Text-to-Speech.]() **Rongjie Huang**, Zhou Zhao, Huadai Liu, Jinglin Liu, and Yi Ren. **ACM MM, 2022**

- We have code released at [![](https://img.shields.io/github/stars/Rongjiehuang/prodiff?style=social&label=Code+Stars)](https://github.com/Rongjiehuang/prodiff), which is a [Trending Project at Github and Paperwithcode.](https://github.motakasoft.com/trending/?d=2022-09-08&l=python) 

<!-- Our work are promoted by different media and forums, such as [Twitter](https://twitter.com/_akhaliq/status/1547393744911097856).  -->

</div>
</div>


<!-- 
- [ProDiff: Progressive Fast Diffusion Model for High-Quality Text-to-Speech.]() **Rongjie Huang**, Zhou Zhao, Huadai Liu, Jinglin Liu, and Yi Ren. **ACM MM, 2022**
 | [**Project**](https://prodiff.github.io/) | [![](https://img.shields.io/github/stars/Rongjiehuang/prodiff?style=social&label=Code+Stars)](https://github.com/Rongjiehuang/prodiff) | [Trending Project at Github and Paperwithcode.](https://github.motakasoft.com/trending/?d=2022-09-08&l=python) | [Twitter](https://twitter.com/_akhaliq/status/1547393744911097856) -->


<!-- - [FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis.](https://arxiv.org/abs/2204.09934) **Rongjie Huang**, Max W.Y. Lam, Jun Wang, Dan Su, Dong Yu, Yi Ren, and Zhou Zhao. **IJCAI, 2022(oral)** 
| [**Project**](https://fastdiff.github.io/) | [![](https://img.shields.io/github/stars/Rongjiehuang/FastDiff?style=social&label=Code+Stars)](https://github.com/Rongjiehuang/FastDiff) | [Trending Project at Github and Paperwithcode.](https://twitter.com/pythontrending/status/1528332486257819651) | [Twitter](https://twitter.com/_akhaliq/status/1517308526691065856) -->



## 2021

- [Multi-Singer: Fast multi-singer singing voice vocoder with a large-scale corpus.](https://dl.acm.org/doi/abs/10.1145/3474085.3475437) **Rongjie Huang**, Feiyang Chen, Yi Ren, Jinglin Liu, Chenye Cui, and Zhou Zhao. **ACM MM, 2021(oral)** 
| [**Project**](https://multi-singer.github.io/) | [![](https://img.shields.io/github/stars/Rongjiehuang/multi-singer?style=social&label=Code+Stars)](https://github.com/Rongjiehuang/multi-singer)

- [SingGAN: Generative Adversarial NetWork For High-Fidelity Singing Voice Generation.](https://arxiv.org/abs/2110.07468) **Rongjie Huang**, Chenye Cui, Feiyang Chen, Yi Ren, Jinglin Liu, and Zhou Zhao. **ACM MM, 2022**  [**Project**](https://singgan.github.io/) 

- [EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model.](https://arxiv.org/abs/2106.09317) Chenye Cui, Yi Ren, Jinglin Liu, Feiyang Chen, **Rongjie Huang**, Mei Li, and Zhou Zhao. **Interspeech, 2021**

- [Bilateral Denoising Diffusion Models.](https://arxiv.org/abs/2108.11514) Max W.Y. Lam, Jun Wang, **Rongjie Huang**, Dan Su, Dong Yu. **Preprint**


## 2020
- [A RD-T Network for Hand Gesture Recognition Based on Millimeter-Wave Sensor.]() **Rongjie Huang**, Zecheng Li, Song Wang, Ronghao Wang, Junjie Li, Zhiwei Xu. **ICSIP 2020**

- [Image Formation Theory and Experiment Based on ML Criterion and EM Algorithm.]() **Rongjie Huang**, Song Wang, Hangfang Zhao. **COA 2021**